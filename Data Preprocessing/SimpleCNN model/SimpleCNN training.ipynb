{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')\n",
    "from Evaluation_procedure.eval_functions import isValid, get_depth, calc_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from Functions import import_raw_colour_image, import_raw_depth_image, show_depth_image, show_img\n",
    "import os\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import math\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the csv data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('..\\data_descriptions.csv', newline='') as csvfile: ###### data_descriptions csv must be in this relative location\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    count = 0\n",
    "    for row in spamreader:\n",
    "        if count == 0:\n",
    "            folder_names = row\n",
    "        else:\n",
    "            num_files = row\n",
    "        count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(num_files)):\n",
    "    num_files[i] = int(num_files[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_numbers = [\"{0:05}\".format(i) for i in range(1, sum(num_files)+1)]\n",
    "colour_filenames = []\n",
    "depth_filenames = []\n",
    "for num in list_of_numbers:\n",
    "    colour_filenames.append(f\"colour_{num}.raw\")\n",
    "    depth_filenames.append(f\"depth_{num}.raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModerateDataset(Dataset):\n",
    "\n",
    "    def __init__(self, col_dir='', depth_dir='', transform=None, trans_on=False):\n",
    "        self.path_names = {}\n",
    "        for folder in folder_names:\n",
    "            self.path_names[f\"{folder}\"] = {}\n",
    "        for folder in folder_names:\n",
    "            self.path_names[f'{folder}']['colour'] = {}\n",
    "            self.path_names[f'{folder}']['depth'] = {}\n",
    "        for i in range(1, num_files[0]):\n",
    "            self.path_names['Sunny']['colour'][f\"{i}\"] = {}\n",
    "            self.path_names['Sunny']['depth'][f\"{i}\"] = {}\n",
    "        print(\"*************MAKE SURE THE PATH FILE IN THE FOR LOOP IS THE BASE IMAGE DIRECTORY ON YOUR COMPUTER**************\")\n",
    "        count = 0\n",
    "        for folder in folder_names:\n",
    "            for i in range(0, num_files[folder_names.index(folder)]):\n",
    "                self.path_names[f'{folder}']['colour'][f'{i+1}'] = Path(f\"C:/Users/Ben/OneDrive - Bournemouth University/Computer Vision/Moderate collection/{folder}/colour/{colour_filenames[count+i]}\")  ## Change this path here!!!!\n",
    "                self.path_names[f'{folder}']['depth'][f'{i+1}'] = Path(f\"C:/Users/Ben/OneDrive - Bournemouth University/Computer Vision/Moderate collection/{folder}/depth/{depth_filenames[count+i]}\")   ## Change this path here!!!!\n",
    "            count = count + num_files[folder_names.index(folder)]\n",
    "        \n",
    "        self.transform = transform\n",
    "        self.col_dir = col_dir\n",
    "        self.depth_dir = depth_dir\n",
    "        self.trans_on = trans_on\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if idx == 0:\n",
    "            \n",
    "            self.col_dir = self.path_names[f'{folder_names[0]}']['colour'][f'{idx+1}']\n",
    "            self.depth_dir = self.path_names[f'{folder_names[0]}']['depth'][f'{idx+1}']\n",
    "        \n",
    "        if (idx>0 and idx <= num_files[0]):  ## 1-500\n",
    "\n",
    "            self.col_dir = self.path_names[f'{folder_names[0]}']['colour'][f'{idx}']\n",
    "            self.depth_dir = self.path_names[f'{folder_names[0]}']['depth'][f'{idx}']\n",
    "\n",
    "        elif (idx > num_files[0] and idx < (sum(num_files[:2])+1)): ## 501 - 1500\n",
    "\n",
    "            self.col_dir = self.path_names[f'{folder_names[1]}']['colour'][f'{idx-num_files[0]}']\n",
    "            self.depth_dir = self.path_names[f'{folder_names[1]}']['depth'][f'{idx-num_files[0]}']\n",
    "\n",
    "        elif (idx > sum(num_files[:2]) and idx < (sum(num_files[:3])+1) ): ## 1501 - 2600\n",
    "\n",
    "            self.col_dir = self.path_names[f'{folder_names[2]}']['colour'][f'{idx-sum(num_files[:2])}'] # -1500\n",
    "            self.depth_dir = self.path_names[f'{folder_names[2]}']['depth'][f'{idx-sum(num_files[:2])}']\n",
    "\n",
    "        elif (idx > sum(num_files[:3]) and idx < (sum(num_files[:4])+1) ): ## 2601 - 5600\n",
    "\n",
    "            self.col_dir = self.path_names[f'{folder_names[3]}']['colour'][f'{idx-sum(num_files[:3])}'] #-2600\n",
    "            self.depth_dir = self.path_names[f'{folder_names[3]}']['depth'][f'{idx-sum(num_files[:3])}']\n",
    "            \n",
    "        elif (idx > sum(num_files[:4]) and idx < (sum(num_files[:5])+1) ): ## 5601 - 7857\n",
    "\n",
    "            self.col_dir = self.path_names[f'{folder_names[4]}']['colour'][f'{idx-sum(num_files[:4])}'] # -5600\n",
    "            self.depth_dir = self.path_names[f'{folder_names[4]}']['depth'][f'{idx-sum(num_files[:4])}']\n",
    "\n",
    "        elif (idx > sum(num_files)):\n",
    "            raise NameError('Index outside of range')\n",
    "\n",
    "        col_img = import_raw_colour_image(self.col_dir)\n",
    "        depth_img = import_raw_depth_image(self.depth_dir)\n",
    "        if self.trans_on == True:\n",
    "            col_img = torch.from_numpy(np.flip(col_img,axis=0).copy()) # apply any transforms\n",
    "            depth_img = torch.from_numpy(np.flip(depth_img,axis=0).copy()) # apply any transforms\n",
    "            col_img = col_img.transpose(0,2)\n",
    "            col_img = col_img.transpose(1,2)\n",
    "        if self.transform: # if any transforms were given to initialiser\n",
    "            col_img = self.transform(col_img) # apply any transforms\n",
    "        return col_img, depth_img\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum(num_files)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "*************MAKE SURE THE PATH FILE IN THE FOR LOOP IS THE BASE IMAGE DIRECTORY ON YOUR COMPUTER**************\n"
    }
   ],
   "source": [
    "total_Data = ModerateDataset(trans_on=True)  ## instancing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is split 80/10/10 train/validation/testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(total_Data))\n",
    "val_size = int((len(total_Data) - train_size)/2)\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(total_Data, [train_size, val_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16\n",
    "tr_dl  = DataLoader(train_dataset,  batch_size=batch_sz, shuffle=True,  num_workers=0)\n",
    "val_dl = DataLoader(val_dataset,  batch_size=batch_sz, shuffle=True,  num_workers=0)\n",
    "test_dl = DataLoader(test_dataset,  batch_size=batch_sz, shuffle=True,  num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(net, tr_dl, val_dl, loss=nn.MSELoss(), epochs=3, lr=3e-3, wd=1e-3):   \n",
    "    # print(\"hello\")\n",
    "    Ltr_hist, Lval_hist = [], []\n",
    "    \n",
    "    opt = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "    # print(\"opt\")\n",
    "    for epoch in trange(epochs):\n",
    "        # print(\"epoch\")\n",
    "        L = []\n",
    "        dl = (iter(tr_dl))\n",
    "        # print(\"dl\")\n",
    "        count_train = 0\n",
    "        for xb, yb in tqdm(dl, leave=False):\n",
    "            # print(\"xb,yb loop\")\n",
    "            xb, yb = xb.float(), yb.float()\n",
    "            xb, yb = xb.cuda(), yb.cuda()\n",
    "            # print(\"xb,yb cuda\")\n",
    "            y_ = net(xb)\n",
    "            # print(\"y_\")\n",
    "            l = loss(y_, yb)\n",
    "            opt.zero_grad()\n",
    "            l.backward()\n",
    "            opt.step()\n",
    "            L.append(l.detach().cpu().numpy())\n",
    "            print(f\"Training on batch {count_train} of {int(train_size/batch_sz)}\")\n",
    "            count_train+= 1\n",
    "\n",
    "        # disable gradient calculations for validation     \n",
    "        for p in net.parameters(): p.requires_grad = False \n",
    "\n",
    "        Lval, Aval = [], []\n",
    "        val_it = iter(val_dl)\n",
    "        val_count = 0\n",
    "        for xb, yb in tqdm(val_it, leave=False):\n",
    "            xb, yb = xb.float(), yb.float()\n",
    "            xb, yb = xb.cuda(), yb.cuda()\n",
    "            y_ = net(xb)\n",
    "            l = loss(y_, yb)\n",
    "            Lval.append(l.detach().cpu().numpy())\n",
    "            Aval.append((y_.max(dim=1)[1] == yb).float().mean().cpu().numpy())\n",
    "            print(f\"Validating on batch {val_count} of {int(val_size/batch_sz)}\")\n",
    "            val_count+= 1\n",
    "\n",
    "        # enable gradient calculations for next epoch \n",
    "        for p in net.parameters(): p.requires_grad = True \n",
    "            \n",
    "        Ltr_hist.append(np.mean(L))\n",
    "        Lval_hist.append(np.mean(Lval))\n",
    "        print(f'training loss: {np.mean(L):0.4f}\\tvalidation loss: {np.mean(Lval):0.4f}\\tvalidation accuracy: {np.mean(Aval):0.2f}')\n",
    "    return Ltr_hist, Lval_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net = nn.Sequential(\n",
    "#     nn.Conv2d(in_channels=3,  out_channels=6, kernel_size=3, stride=1, padding=1), \n",
    "#     nn.ReLU(),\n",
    "#     nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, stride=1, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.ConvTranspose2d(in_channels = 12, out_channels=6, kernel_size=3, stride=1, padding=1),\n",
    "#     nn.ReLU(),\n",
    "#     nn.ConvTranspose2d(in_channels = 6, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "#     nn.ReLU()\n",
    "# ).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary(net, (3,720,1280), 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the fit function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network\n",
    "Takes ~30 mins/epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Ltr_hist, Lval_hist = fit(net.cuda(), tr_dl, val_dl, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING A SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'model_20042020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_load_trained_model = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Sequential(\n  (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (1): ReLU()\n  (2): Conv2d(6, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (3): ReLU()\n  (4): ConvTranspose2d(12, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (5): ReLU()\n  (6): ConvTranspose2d(6, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (7): ReLU()\n)"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "re_load_trained_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "297efdbb54d24488ac29d4786c38d369"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": ""
    }
   ],
   "source": [
    "count_test_batches = 0\n",
    "for xb, yb in tqdm(test_dl, leave=False):\n",
    "    if count_test_batches == 0:\n",
    "        # initialise list of predicted depths\n",
    "        numpy_depth_prediction = [None]*int(val_size/batch_sz+1)\n",
    "        gt_depths = [None]*int(val_size/batch_sz+1)\n",
    "        for i in range(0, int(val_size/batch_sz+1)):\n",
    "            numpy_depth_prediction[i] = [None]*xb.shape[0]\n",
    "            gt_depths[i] = [None]*xb.shape[0]\n",
    "    # transform data into floats and then place on gpu\n",
    "    xb, yb = xb.float(), yb.float()\n",
    "    xb, yb = xb.cuda(), yb.cuda()\n",
    "\n",
    "    # run the x's through the trained network to predict their depth maps\n",
    "    prediction = re_load_trained_model(xb)\n",
    "    \n",
    "    # save each predicted depth map in the batch to a list as a numpy array\n",
    "    for i in range(0, xb.shape[0]):\n",
    "        # reshape the predictions to the correct size:(720,1280) from (1,720,1280)\n",
    "        numpy_depth_prediction[count_test_batches][i] = np.reshape(prediction[i].cpu().detach().numpy(), (720,1280))\n",
    "        # save ground truth depths to list\n",
    "        gt_depths[count_test_batches][i] = yb[i].cpu().detach().numpy()\n",
    "    count_test_batches += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialise a dictionary for holding the calculated errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_dictionary = {}\n",
    "for i in range(int(val_size/batch_sz+1)):\n",
    "        error_dictionary[f\"{i}\"] = {}\n",
    "for i in range(int(val_size/batch_sz+1)):\n",
    "    for j in range(batch_sz):\n",
    "        error_dictionary[f\"{i}\"][f\"{j}\"] = {}\n",
    "# error_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n2\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n3\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n4\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n5\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n6\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n7\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n8\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n9\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n10\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n11\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n12\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n13\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n14\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n15\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n16\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n17\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n18\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\n19\n20\n20\n20\n20\n20\n20\n20\n20\n20\n20\n20\n20\n20\n20\n20\n21\n21\n21\n21\n21\n21\n21\n21\n21\n21\n21\n21\n21\n21\n21\n22\n22\n22\n22\n22\n22\n22\n22\n22\n22\n22\n22\n22\n22\n22\n23\n23\n23\n23\n23\n23\n23\n23\n23\n23\n23\n23\n23\n23\n23\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n24\n25\n25\n25\n25\n25\n25\n25\n25\n25\n25\n25\n25\n25\n25\n25\n26\n26\n26\n26\n26\n26\n26\n26\n26\n26\n26\n26\n26\n26\n26\n27\n27\n27\n27\n27\n27\n27\n27\n27\n27\n27\n27\n27\n27\n27\n28\n28\n28\n28\n28\n28\n28\n28\n28\n28\n28\n28\n28\n28\n28\n29\n29\n29\n29\n29\n29\n29\n29\n29\n29\n29\n29\n29\n29\n29\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n30\n31\n31\n31\n31\n31\n31\n31\n31\n31\n31\n31\n31\n31\n31\n31\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n32\n33\n33\n33\n33\n33\n33\n33\n33\n33\n33\n33\n33\n33\n33\n33\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n34\n35\n35\n35\n35\n35\n35\n35\n35\n35\n35\n35\n35\n35\n35\n35\n36\n36\n36\n36\n36\n36\n36\n36\n36\n36\n36\n36\n36\n36\n36\n37\n37\n37\n37\n37\n37\n37\n37\n37\n37\n37\n37\n37\n37\n37\n38\n38\n38\n38\n38\n38\n38\n38\n38\n38\n38\n38\n38\n38\n38\n39\n39\n39\n39\n39\n39\n39\n39\n39\n39\n39\n39\n39\n39\n39\n40\n40\n40\n40\n40\n40\n40\n40\n40\n40\n40\n40\n40\n40\n40\n41\n41\n41\n41\n41\n41\n41\n41\n41\n41\n41\n41\n41\n41\n41\n42\n42\n42\n42\n42\n42\n42\n42\n42\n42\n42\n42\n42\n42\n42\n43\n43\n43\n43\n43\n43\n43\n43\n43\n43\n43\n43\n43\n43\n43\n44\n44\n44\n44\n44\n44\n44\n44\n44\n44\n44\n44\n44\n44\n44\n45\n45\n45\n45\n45\n45\n45\n45\n45\n45\n45\n45\n45\n45\n45\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n46\n47\n47\n47\n47\n47\n47\n47\n47\n47\n47\n47\n47\n47\n47\n47\n48\n48\n48\n48\n48\n48\n48\n48\n48\n48\n48\n48\n48\n48\n48\n49\n49\n"
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Ben\\Documents\\EngD 1st year\\Computer Vision\\Group project\\Github\\depth_estimation\\Evaluation_procedure\\eval_functions.py\u001b[0m in \u001b[0;36mcalc_errors\u001b[1;34m(pred_depth, grndt_depth)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0msqr_rel_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m     \u001b[1;31m# 9\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mvalid_pixels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m   \u001b[1;31m# valid pixel count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred_depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrndt_depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpred_depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrndt_depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mu\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_depth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(int(val_size/batch_sz+1)):\n",
    "    if i == 49:\n",
    "        error_dictionary[f\"{i}\"][f\"{0}\"] = calc_errors(numpy_depth_prediction[i][0], gt_depths[i][0])\n",
    "        error_dictionary[f\"{i}\"][f\"{1}\"] = calc_errors(numpy_depth_prediction[i][1], gt_depths[i][1])\n",
    "    else:\n",
    "        for j in range(batch_sz-1): # batch_sz):\n",
    "            error_dictionary[f\"{i}\"][f\"{j}\"] = calc_errors(numpy_depth_prediction[i][j], gt_depths[i][j])\n",
    "    print(f\"Calculating errors for batch {i} of {int(val_size/batch_sz)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate average errors over test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 0 ns\n"
    }
   ],
   "source": [
    "%%time\n",
    "# initialisation of average errors\n",
    "difference_err_avg = 0\n",
    "sqr_diff_err_avg = 0\n",
    "inv_err_avg = 0\n",
    "inv_sqr_err_avg = 0\n",
    "log_err_avg = 0\n",
    "log_sqr_err_avg = 0\n",
    "log_non_abs_err_avg = 0\n",
    "abs_rel_err_avg = 0\n",
    "sqr_rel_err_avg = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 2.44 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(0, int(val_size/batch_sz)):\n",
    "    for j in range(0, batch_sz-1):\n",
    "        difference_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][0]\n",
    "        sqr_diff_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][1]\n",
    "        inv_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][2]\n",
    "        inv_sqr_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][3]\n",
    "        log_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][4]\n",
    "        log_sqr_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][5]\n",
    "        log_non_abs_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][6]\n",
    "        abs_rel_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][7]\n",
    "        sqr_rel_err_avg += error_dictionary[f\"{i}\"][f\"{j}\"][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.15349015485873604 0.20413706169302126 216.92079890689172 449.87569844827283 1.4395006203028675 1.6912679620310802 1.0779036028588291 17.408615003311972 57917.195704816244\n"
    }
   ],
   "source": [
    "## divide by number of images to get average error\n",
    "difference_err_avg /= (val_size)\n",
    "sqr_diff_err_avg /= (val_size)\n",
    "inv_err_avg /= (val_size)\n",
    "inv_sqr_err_avg /= (val_size)\n",
    "log_err_avg /= (val_size)\n",
    "log_sqr_err_avg /= (val_size)\n",
    "log_non_abs_err_avg /= (val_size)\n",
    "abs_rel_err_avg /= (val_size)\n",
    "sqr_rel_err_avg /= (val_size)\n",
    "print(difference_err_avg, sqr_diff_err_avg, inv_err_avg, inv_sqr_err_avg, log_err_avg, log_sqr_err_avg, log_non_abs_err_avg, abs_rel_err_avg, sqr_rel_err_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate standard deviation in average errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise difference counters\n",
    "difference_err_count = 0\n",
    "sqr_diff_err_count = 0\n",
    "inv_err_count = 0\n",
    "inv_sqr_err_count = 0\n",
    "log_err_count = 0\n",
    "log_sqr_err_count = 0\n",
    "log_non_abs_err_count = 0\n",
    "abs_rel_err_count = 0\n",
    "sqr_rel_err_count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 6.97 ms\n"
    }
   ],
   "source": [
    "%%time\n",
    "# sum squared differences\n",
    "for i in range(0, int(val_size/batch_sz)):\n",
    "    for j in range(0, batch_sz-1):\n",
    "            difference_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - difference_err_avg)**2\n",
    "            sqr_diff_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - sqr_diff_err_avg)**2\n",
    "            inv_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - inv_err_avg)**2\n",
    "            inv_sqr_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - inv_sqr_err_avg)**2\n",
    "            log_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - log_err_avg)**2\n",
    "            log_sqr_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - log_sqr_err_avg)**2\n",
    "            log_non_abs_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - log_non_abs_err_avg)**2\n",
    "            abs_rel_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - abs_rel_err_avg)**2\n",
    "            sqr_rel_err_count += (error_dictionary[f\"{i}\"][f\"{j}\"][0] - sqr_rel_err_avg)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide by number of test images\n",
    "difference_err_count /= val_size\n",
    "sqr_diff_err_count /= val_size\n",
    "inv_err_count /= val_size\n",
    "inv_sqr_err_count /= val_size\n",
    "log_err_count /= val_size\n",
    "log_sqr_err_count /= val_size\n",
    "log_non_abs_err_count /= val_size\n",
    "abs_rel_err_count /= val_size\n",
    "sqr_rel_err_count /= val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.0031852591413042137 0.003451686762223687 7.476418605301046 15.51154946000541 0.04410363930439457 0.05276895537876926 0.031676132664665964 0.594808591100741 1997.6868841917874\n"
    }
   ],
   "source": [
    "# square root\n",
    "difference_err_sigma = math.sqrt(difference_err_count)\n",
    "sqr_diff_err_sigma = math.sqrt(sqr_diff_err_count)\n",
    "inv_err_sigma = math.sqrt(inv_err_count)\n",
    "inv_sqr_err_sigma = math.sqrt(inv_sqr_err_count)\n",
    "log_err_sigma = math.sqrt(log_err_count)\n",
    "log_sqr_err_sigma = math.sqrt(log_sqr_err_count)\n",
    "log_non_abs_err_sigma = math.sqrt(log_non_abs_err_count)\n",
    "abs_rel_err_sigma = math.sqrt(abs_rel_err_count)\n",
    "sqr_rel_err_sigma = math.sqrt(sqr_rel_err_count)\n",
    "print(difference_err_sigma, sqr_diff_err_sigma, inv_err_sigma, inv_sqr_err_sigma, log_err_sigma, log_sqr_err_sigma, log_non_abs_err_sigma, abs_rel_err_sigma, sqr_rel_err_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_errors = [difference_err_avg, sqr_diff_err_avg, inv_err_avg, inv_sqr_err_avg, log_err_avg, log_sqr_err_avg, log_non_abs_err_avg, abs_rel_err_avg, sqr_rel_err_avg]\n",
    "std_devs = [difference_err_sigma, sqr_diff_err_sigma, inv_err_sigma, inv_sqr_err_sigma, log_err_sigma, log_sqr_err_sigma, log_non_abs_err_sigma, abs_rel_err_sigma, sqr_rel_err_sigma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Err = 0.153 \t +-\t0.003\nErr = 0.204 \t +-\t0.003\nErr = 216.921 \t +-\t7.476\nErr = 449.876 \t +-\t15.512\nErr = 1.440 \t +-\t0.044\nErr = 1.691 \t +-\t0.053\nErr = 1.078 \t +-\t0.032\nErr = 17.409 \t +-\t0.595\nErr = 57917.196 \t +-\t1997.687\n"
    }
   ],
   "source": [
    "for mean, std in zip(mean_errors, std_devs):\n",
    "    print(\"Err = \"\"{:.3f}\".format(mean), \"\\t +-\\t\"\"{:.3f}\".format(std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train dataloader is called tr_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Whirrrrrr calculating..... 0 of 392.8125\nWhirrrrrr calculating..... 1 of 392.8125\nWhirrrrrr calculating..... 2 of 392.8125\nWhirrrrrr calculating..... 3 of 392.8125\nWhirrrrrr calculating..... 4 of 392.8125\nWhirrrrrr calculating..... 5 of 392.8125\nWhirrrrrr calculating..... 6 of 392.8125\nWhirrrrrr calculating..... 7 of 392.8125\nWhirrrrrr calculating..... 8 of 392.8125\nWhirrrrrr calculating..... 9 of 392.8125\nWhirrrrrr calculating..... 10 of 392.8125\nWhirrrrrr calculating..... 11 of 392.8125\nWhirrrrrr calculating..... 12 of 392.8125\nWhirrrrrr calculating..... 13 of 392.8125\nWhirrrrrr calculating..... 14 of 392.8125\nWhirrrrrr calculating..... 15 of 392.8125\nWhirrrrrr calculating..... 16 of 392.8125\nWhirrrrrr calculating..... 17 of 392.8125\nWhirrrrrr calculating..... 18 of 392.8125\nWhirrrrrr calculating..... 19 of 392.8125\nWhirrrrrr calculating..... 20 of 392.8125\nWhirrrrrr calculating..... 21 of 392.8125\nWhirrrrrr calculating..... 22 of 392.8125\nWhirrrrrr calculating..... 23 of 392.8125\nWhirrrrrr calculating..... 24 of 392.8125\nWhirrrrrr calculating..... 25 of 392.8125\nWhirrrrrr calculating..... 26 of 392.8125\nWhirrrrrr calculating..... 27 of 392.8125\nWhirrrrrr calculating..... 28 of 392.8125\nWhirrrrrr calculating..... 29 of 392.8125\nWhirrrrrr calculating..... 30 of 392.8125\nWhirrrrrr calculating..... 31 of 392.8125\nWhirrrrrr calculating..... 32 of 392.8125\nWhirrrrrr calculating..... 33 of 392.8125\nWhirrrrrr calculating..... 34 of 392.8125\nWhirrrrrr calculating..... 35 of 392.8125\nWhirrrrrr calculating..... 36 of 392.8125\nWhirrrrrr calculating..... 37 of 392.8125\nWhirrrrrr calculating..... 38 of 392.8125\nWhirrrrrr calculating..... 39 of 392.8125\nWhirrrrrr calculating..... 40 of 392.8125\nWhirrrrrr calculating..... 41 of 392.8125\nWhirrrrrr calculating..... 42 of 392.8125\nWhirrrrrr calculating..... 43 of 392.8125\nWhirrrrrr calculating..... 44 of 392.8125\nWhirrrrrr calculating..... 45 of 392.8125\nWhirrrrrr calculating..... 46 of 392.8125\nWhirrrrrr calculating..... 47 of 392.8125\nWhirrrrrr calculating..... 48 of 392.8125\nWhirrrrrr calculating..... 49 of 392.8125\nWhirrrrrr calculating..... 50 of 392.8125\nWhirrrrrr calculating..... 51 of 392.8125\nWhirrrrrr calculating..... 52 of 392.8125\nWhirrrrrr calculating..... 53 of 392.8125\nWhirrrrrr calculating..... 54 of 392.8125\nWhirrrrrr calculating..... 55 of 392.8125\nWhirrrrrr calculating..... 56 of 392.8125\nWhirrrrrr calculating..... 57 of 392.8125\nWhirrrrrr calculating..... 58 of 392.8125\nWhirrrrrr calculating..... 59 of 392.8125\nWhirrrrrr calculating..... 60 of 392.8125\nWhirrrrrr calculating..... 61 of 392.8125\nWhirrrrrr calculating..... 62 of 392.8125\nWhirrrrrr calculating..... 63 of 392.8125\nWhirrrrrr calculating..... 64 of 392.8125\nWhirrrrrr calculating..... 65 of 392.8125\nWhirrrrrr calculating..... 66 of 392.8125\nWhirrrrrr calculating..... 67 of 392.8125\nWhirrrrrr calculating..... 68 of 392.8125\nWhirrrrrr calculating..... 69 of 392.8125\nWhirrrrrr calculating..... 70 of 392.8125\nWhirrrrrr calculating..... 71 of 392.8125\nWhirrrrrr calculating..... 72 of 392.8125\nWhirrrrrr calculating..... 73 of 392.8125\nWhirrrrrr calculating..... 74 of 392.8125\nWhirrrrrr calculating..... 75 of 392.8125\nWhirrrrrr calculating..... 76 of 392.8125\nWhirrrrrr calculating..... 77 of 392.8125\nWhirrrrrr calculating..... 78 of 392.8125\nWhirrrrrr calculating..... 79 of 392.8125\nWhirrrrrr calculating..... 80 of 392.8125\nWhirrrrrr calculating..... 81 of 392.8125\nWhirrrrrr calculating..... 82 of 392.8125\nWhirrrrrr calculating..... 83 of 392.8125\nWhirrrrrr calculating..... 84 of 392.8125\nWhirrrrrr calculating..... 85 of 392.8125\nWhirrrrrr calculating..... 86 of 392.8125\nWhirrrrrr calculating..... 87 of 392.8125\nWhirrrrrr calculating..... 88 of 392.8125\nWhirrrrrr calculating..... 89 of 392.8125\nWhirrrrrr calculating..... 90 of 392.8125\nWhirrrrrr calculating..... 91 of 392.8125\nWhirrrrrr calculating..... 92 of 392.8125\nWhirrrrrr calculating..... 93 of 392.8125\nWhirrrrrr calculating..... 94 of 392.8125\nWhirrrrrr calculating..... 95 of 392.8125\nWhirrrrrr calculating..... 96 of 392.8125\nWhirrrrrr calculating..... 97 of 392.8125\nWhirrrrrr calculating..... 98 of 392.8125\nWhirrrrrr calculating..... 99 of 392.8125\nWhirrrrrr calculating..... 100 of 392.8125\nWhirrrrrr calculating..... 101 of 392.8125\nWhirrrrrr calculating..... 102 of 392.8125\nWhirrrrrr calculating..... 103 of 392.8125\nWhirrrrrr calculating..... 104 of 392.8125\nWhirrrrrr calculating..... 105 of 392.8125\nWhirrrrrr calculating..... 106 of 392.8125\nWhirrrrrr calculating..... 107 of 392.8125\nWhirrrrrr calculating..... 108 of 392.8125\nWhirrrrrr calculating..... 109 of 392.8125\nWhirrrrrr calculating..... 110 of 392.8125\nWhirrrrrr calculating..... 111 of 392.8125\nWhirrrrrr calculating..... 112 of 392.8125\nWhirrrrrr calculating..... 113 of 392.8125\nWhirrrrrr calculating..... 114 of 392.8125\nWhirrrrrr calculating..... 115 of 392.8125\nWhirrrrrr calculating..... 116 of 392.8125\nWhirrrrrr calculating..... 117 of 392.8125\nWhirrrrrr calculating..... 118 of 392.8125\nWhirrrrrr calculating..... 119 of 392.8125\nWhirrrrrr calculating..... 120 of 392.8125\nWhirrrrrr calculating..... 121 of 392.8125\nWhirrrrrr calculating..... 122 of 392.8125\nWhirrrrrr calculating..... 123 of 392.8125\nWhirrrrrr calculating..... 124 of 392.8125\nWhirrrrrr calculating..... 125 of 392.8125\nWhirrrrrr calculating..... 126 of 392.8125\nWhirrrrrr calculating..... 127 of 392.8125\nWhirrrrrr calculating..... 128 of 392.8125\nWhirrrrrr calculating..... 129 of 392.8125\nWhirrrrrr calculating..... 130 of 392.8125\nWhirrrrrr calculating..... 131 of 392.8125\nWhirrrrrr calculating..... 132 of 392.8125\nWhirrrrrr calculating..... 133 of 392.8125\nWhirrrrrr calculating..... 134 of 392.8125\nWhirrrrrr calculating..... 135 of 392.8125\nWhirrrrrr calculating..... 136 of 392.8125\nWhirrrrrr calculating..... 137 of 392.8125\nWhirrrrrr calculating..... 138 of 392.8125\nWhirrrrrr calculating..... 139 of 392.8125\nWhirrrrrr calculating..... 140 of 392.8125\nWhirrrrrr calculating..... 141 of 392.8125\nWhirrrrrr calculating..... 142 of 392.8125\nWhirrrrrr calculating..... 143 of 392.8125\nWhirrrrrr calculating..... 144 of 392.8125\nWhirrrrrr calculating..... 145 of 392.8125\nWhirrrrrr calculating..... 146 of 392.8125\nWhirrrrrr calculating..... 147 of 392.8125\nWhirrrrrr calculating..... 148 of 392.8125\nWhirrrrrr calculating..... 149 of 392.8125\nWhirrrrrr calculating..... 150 of 392.8125\nWhirrrrrr calculating..... 151 of 392.8125\nWhirrrrrr calculating..... 152 of 392.8125\nWhirrrrrr calculating..... 153 of 392.8125\nWhirrrrrr calculating..... 154 of 392.8125\nWhirrrrrr calculating..... 155 of 392.8125\nWhirrrrrr calculating..... 156 of 392.8125\nWhirrrrrr calculating..... 157 of 392.8125\nWhirrrrrr calculating..... 158 of 392.8125\nWhirrrrrr calculating..... 159 of 392.8125\nWhirrrrrr calculating..... 160 of 392.8125\nWhirrrrrr calculating..... 161 of 392.8125\nWhirrrrrr calculating..... 162 of 392.8125\nWhirrrrrr calculating..... 163 of 392.8125\nWhirrrrrr calculating..... 164 of 392.8125\nWhirrrrrr calculating..... 165 of 392.8125\nWhirrrrrr calculating..... 166 of 392.8125\nWhirrrrrr calculating..... 167 of 392.8125\nWhirrrrrr calculating..... 168 of 392.8125\nWhirrrrrr calculating..... 169 of 392.8125\nWhirrrrrr calculating..... 170 of 392.8125\nWhirrrrrr calculating..... 171 of 392.8125\nWhirrrrrr calculating..... 172 of 392.8125\nWhirrrrrr calculating..... 173 of 392.8125\nWhirrrrrr calculating..... 174 of 392.8125\nWhirrrrrr calculating..... 175 of 392.8125\nWhirrrrrr calculating..... 176 of 392.8125\nWhirrrrrr calculating..... 177 of 392.8125\nWhirrrrrr calculating..... 178 of 392.8125\nWhirrrrrr calculating..... 179 of 392.8125\nWhirrrrrr calculating..... 180 of 392.8125\nWhirrrrrr calculating..... 181 of 392.8125\nWhirrrrrr calculating..... 182 of 392.8125\nWhirrrrrr calculating..... 183 of 392.8125\nWhirrrrrr calculating..... 184 of 392.8125\nWhirrrrrr calculating..... 185 of 392.8125\nWhirrrrrr calculating..... 186 of 392.8125\nWhirrrrrr calculating..... 187 of 392.8125\nWhirrrrrr calculating..... 188 of 392.8125\nWhirrrrrr calculating..... 189 of 392.8125\nWhirrrrrr calculating..... 190 of 392.8125\nWhirrrrrr calculating..... 191 of 392.8125\nWhirrrrrr calculating..... 192 of 392.8125\nWhirrrrrr calculating..... 193 of 392.8125\nWhirrrrrr calculating..... 194 of 392.8125\nWhirrrrrr calculating..... 195 of 392.8125\nWhirrrrrr calculating..... 196 of 392.8125\nWhirrrrrr calculating..... 197 of 392.8125\nWhirrrrrr calculating..... 198 of 392.8125\nWhirrrrrr calculating..... 199 of 392.8125\nWhirrrrrr calculating..... 200 of 392.8125\nWhirrrrrr calculating..... 201 of 392.8125\nWhirrrrrr calculating..... 202 of 392.8125\nWhirrrrrr calculating..... 203 of 392.8125\nWhirrrrrr calculating..... 204 of 392.8125\nWhirrrrrr calculating..... 205 of 392.8125\nWhirrrrrr calculating..... 206 of 392.8125\nWhirrrrrr calculating..... 207 of 392.8125\nWhirrrrrr calculating..... 208 of 392.8125\nWhirrrrrr calculating..... 209 of 392.8125\nWhirrrrrr calculating..... 210 of 392.8125\nWhirrrrrr calculating..... 211 of 392.8125\nWhirrrrrr calculating..... 212 of 392.8125\nWhirrrrrr calculating..... 213 of 392.8125\nWhirrrrrr calculating..... 214 of 392.8125\nWhirrrrrr calculating..... 215 of 392.8125\nWhirrrrrr calculating..... 216 of 392.8125\nWhirrrrrr calculating..... 217 of 392.8125\nWhirrrrrr calculating..... 218 of 392.8125\nWhirrrrrr calculating..... 219 of 392.8125\nWhirrrrrr calculating..... 220 of 392.8125\nWhirrrrrr calculating..... 221 of 392.8125\nWhirrrrrr calculating..... 222 of 392.8125\nWhirrrrrr calculating..... 223 of 392.8125\nWhirrrrrr calculating..... 224 of 392.8125\nWhirrrrrr calculating..... 225 of 392.8125\nWhirrrrrr calculating..... 226 of 392.8125\nWhirrrrrr calculating..... 227 of 392.8125\nWhirrrrrr calculating..... 228 of 392.8125\nWhirrrrrr calculating..... 229 of 392.8125\nWhirrrrrr calculating..... 230 of 392.8125\nWhirrrrrr calculating..... 231 of 392.8125\nWhirrrrrr calculating..... 232 of 392.8125\nWhirrrrrr calculating..... 233 of 392.8125\nWhirrrrrr calculating..... 234 of 392.8125\nWhirrrrrr calculating..... 235 of 392.8125\nWhirrrrrr calculating..... 236 of 392.8125\nWhirrrrrr calculating..... 237 of 392.8125\nWhirrrrrr calculating..... 238 of 392.8125\nWhirrrrrr calculating..... 239 of 392.8125\nWhirrrrrr calculating..... 240 of 392.8125\nWhirrrrrr calculating..... 241 of 392.8125\nWhirrrrrr calculating..... 242 of 392.8125\nWhirrrrrr calculating..... 243 of 392.8125\nWhirrrrrr calculating..... 244 of 392.8125\nWhirrrrrr calculating..... 245 of 392.8125\nWhirrrrrr calculating..... 246 of 392.8125\nWhirrrrrr calculating..... 247 of 392.8125\nWhirrrrrr calculating..... 248 of 392.8125\nWhirrrrrr calculating..... 249 of 392.8125\nWhirrrrrr calculating..... 250 of 392.8125\nWhirrrrrr calculating..... 251 of 392.8125\nWhirrrrrr calculating..... 252 of 392.8125\nWhirrrrrr calculating..... 253 of 392.8125\nWhirrrrrr calculating..... 254 of 392.8125\nWhirrrrrr calculating..... 255 of 392.8125\nWhirrrrrr calculating..... 256 of 392.8125\nWhirrrrrr calculating..... 257 of 392.8125\nWhirrrrrr calculating..... 258 of 392.8125\nWhirrrrrr calculating..... 259 of 392.8125\nWhirrrrrr calculating..... 260 of 392.8125\nWhirrrrrr calculating..... 261 of 392.8125\nWhirrrrrr calculating..... 262 of 392.8125\nWhirrrrrr calculating..... 263 of 392.8125\nWhirrrrrr calculating..... 264 of 392.8125\nWhirrrrrr calculating..... 265 of 392.8125\nWhirrrrrr calculating..... 266 of 392.8125\nWhirrrrrr calculating..... 267 of 392.8125\nWhirrrrrr calculating..... 268 of 392.8125\nWhirrrrrr calculating..... 269 of 392.8125\nWhirrrrrr calculating..... 270 of 392.8125\nWhirrrrrr calculating..... 271 of 392.8125\nWhirrrrrr calculating..... 272 of 392.8125\nWhirrrrrr calculating..... 273 of 392.8125\nWhirrrrrr calculating..... 274 of 392.8125\nWhirrrrrr calculating..... 275 of 392.8125\nWhirrrrrr calculating..... 276 of 392.8125\nWhirrrrrr calculating..... 277 of 392.8125\nWhirrrrrr calculating..... 278 of 392.8125\nWhirrrrrr calculating..... 279 of 392.8125\nWhirrrrrr calculating..... 280 of 392.8125\nWhirrrrrr calculating..... 281 of 392.8125\nWhirrrrrr calculating..... 282 of 392.8125\nWhirrrrrr calculating..... 283 of 392.8125\nWhirrrrrr calculating..... 284 of 392.8125\nWhirrrrrr calculating..... 285 of 392.8125\nWhirrrrrr calculating..... 286 of 392.8125\nWhirrrrrr calculating..... 287 of 392.8125\nWhirrrrrr calculating..... 288 of 392.8125\nWhirrrrrr calculating..... 289 of 392.8125\nWhirrrrrr calculating..... 290 of 392.8125\nWhirrrrrr calculating..... 291 of 392.8125\nWhirrrrrr calculating..... 292 of 392.8125\nWhirrrrrr calculating..... 293 of 392.8125\nWhirrrrrr calculating..... 294 of 392.8125\nWhirrrrrr calculating..... 295 of 392.8125\nWhirrrrrr calculating..... 296 of 392.8125\nWhirrrrrr calculating..... 297 of 392.8125\nWhirrrrrr calculating..... 298 of 392.8125\nWhirrrrrr calculating..... 299 of 392.8125\nWhirrrrrr calculating..... 300 of 392.8125\nWhirrrrrr calculating..... 301 of 392.8125\nWhirrrrrr calculating..... 302 of 392.8125\nWhirrrrrr calculating..... 303 of 392.8125\nWhirrrrrr calculating..... 304 of 392.8125\nWhirrrrrr calculating..... 305 of 392.8125\nWhirrrrrr calculating..... 306 of 392.8125\nWhirrrrrr calculating..... 307 of 392.8125\nWhirrrrrr calculating..... 308 of 392.8125\nWhirrrrrr calculating..... 309 of 392.8125\nWhirrrrrr calculating..... 310 of 392.8125\nWhirrrrrr calculating..... 311 of 392.8125\nWhirrrrrr calculating..... 312 of 392.8125\nWhirrrrrr calculating..... 313 of 392.8125\nWhirrrrrr calculating..... 314 of 392.8125\nWhirrrrrr calculating..... 315 of 392.8125\nWhirrrrrr calculating..... 316 of 392.8125\nWhirrrrrr calculating..... 317 of 392.8125\nWhirrrrrr calculating..... 318 of 392.8125\nWhirrrrrr calculating..... 319 of 392.8125\nWhirrrrrr calculating..... 320 of 392.8125\nWhirrrrrr calculating..... 321 of 392.8125\nWhirrrrrr calculating..... 322 of 392.8125\nWhirrrrrr calculating..... 323 of 392.8125\nWhirrrrrr calculating..... 324 of 392.8125\nWhirrrrrr calculating..... 325 of 392.8125\nWhirrrrrr calculating..... 326 of 392.8125\nWhirrrrrr calculating..... 327 of 392.8125\nWhirrrrrr calculating..... 328 of 392.8125\nWhirrrrrr calculating..... 329 of 392.8125\nWhirrrrrr calculating..... 330 of 392.8125\nWhirrrrrr calculating..... 331 of 392.8125\nWhirrrrrr calculating..... 332 of 392.8125\nWhirrrrrr calculating..... 333 of 392.8125\nWhirrrrrr calculating..... 334 of 392.8125\nWhirrrrrr calculating..... 335 of 392.8125\nWhirrrrrr calculating..... 336 of 392.8125\nWhirrrrrr calculating..... 337 of 392.8125\nWhirrrrrr calculating..... 338 of 392.8125\nWhirrrrrr calculating..... 339 of 392.8125\nWhirrrrrr calculating..... 340 of 392.8125\nWhirrrrrr calculating..... 341 of 392.8125\nWhirrrrrr calculating..... 342 of 392.8125\nWhirrrrrr calculating..... 343 of 392.8125\nWhirrrrrr calculating..... 344 of 392.8125\nWhirrrrrr calculating..... 345 of 392.8125\nWhirrrrrr calculating..... 346 of 392.8125\nWhirrrrrr calculating..... 347 of 392.8125\nWhirrrrrr calculating..... 348 of 392.8125\nWhirrrrrr calculating..... 349 of 392.8125\nWhirrrrrr calculating..... 350 of 392.8125\nWhirrrrrr calculating..... 351 of 392.8125\nWhirrrrrr calculating..... 352 of 392.8125\nWhirrrrrr calculating..... 353 of 392.8125\nWhirrrrrr calculating..... 354 of 392.8125\nWhirrrrrr calculating..... 355 of 392.8125\nWhirrrrrr calculating..... 356 of 392.8125\nWhirrrrrr calculating..... 357 of 392.8125\nWhirrrrrr calculating..... 358 of 392.8125\nWhirrrrrr calculating..... 359 of 392.8125\nWhirrrrrr calculating..... 360 of 392.8125\nWhirrrrrr calculating..... 361 of 392.8125\nWhirrrrrr calculating..... 362 of 392.8125\nWhirrrrrr calculating..... 363 of 392.8125\nWhirrrrrr calculating..... 364 of 392.8125\nWhirrrrrr calculating..... 365 of 392.8125\nWhirrrrrr calculating..... 366 of 392.8125\nWhirrrrrr calculating..... 367 of 392.8125\nWhirrrrrr calculating..... 368 of 392.8125\nWhirrrrrr calculating..... 369 of 392.8125\nWhirrrrrr calculating..... 370 of 392.8125\nWhirrrrrr calculating..... 371 of 392.8125\nWhirrrrrr calculating..... 372 of 392.8125\nWhirrrrrr calculating..... 373 of 392.8125\nWhirrrrrr calculating..... 374 of 392.8125\nWhirrrrrr calculating..... 375 of 392.8125\nWhirrrrrr calculating..... 376 of 392.8125\nWhirrrrrr calculating..... 377 of 392.8125\nWhirrrrrr calculating..... 378 of 392.8125\nWhirrrrrr calculating..... 379 of 392.8125\nWhirrrrrr calculating..... 380 of 392.8125\nWhirrrrrr calculating..... 381 of 392.8125\nWhirrrrrr calculating..... 382 of 392.8125\nWhirrrrrr calculating..... 383 of 392.8125\nWhirrrrrr calculating..... 384 of 392.8125\nWhirrrrrr calculating..... 385 of 392.8125\nWhirrrrrr calculating..... 386 of 392.8125\nWhirrrrrr calculating..... 387 of 392.8125\nWhirrrrrr calculating..... 388 of 392.8125\nWhirrrrrr calculating..... 389 of 392.8125\nWhirrrrrr calculating..... 390 of 392.8125\nWhirrrrrr calculating..... 391 of 392.8125\nWhirrrrrr calculating..... 392 of 392.8125\n"
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'count_var' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a6474dff2bc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcount_var\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtr_dl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mbatch_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_var' is not defined"
     ]
    }
   ],
   "source": [
    "mean = 0.0\n",
    "count_mn = 0\n",
    "for images, _ in tr_dl:\n",
    "    images = images.float()\n",
    "    batch_samples = images.size(0) \n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    mean += images.mean(2).sum(0)\n",
    "    print(f\"Whirrrrrr calculating..... {count_mn} of {train_size/batch_sz}\")\n",
    "    count_mn+= 1\n",
    "mean = mean / len(tr_dl.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 98.2207, 101.6702, 102.9898])"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Whirrrrrr calculating..... 0 of 392.8125\nWhirrrrrr calculating..... 1 of 392.8125\nWhirrrrrr calculating..... 2 of 392.8125\nWhirrrrrr calculating..... 3 of 392.8125\nWhirrrrrr calculating..... 4 of 392.8125\nWhirrrrrr calculating..... 5 of 392.8125\nWhirrrrrr calculating..... 6 of 392.8125\nWhirrrrrr calculating..... 7 of 392.8125\nWhirrrrrr calculating..... 8 of 392.8125\nWhirrrrrr calculating..... 9 of 392.8125\nWhirrrrrr calculating..... 10 of 392.8125\nWhirrrrrr calculating..... 11 of 392.8125\nWhirrrrrr calculating..... 12 of 392.8125\nWhirrrrrr calculating..... 13 of 392.8125\nWhirrrrrr calculating..... 14 of 392.8125\nWhirrrrrr calculating..... 15 of 392.8125\nWhirrrrrr calculating..... 16 of 392.8125\nWhirrrrrr calculating..... 17 of 392.8125\nWhirrrrrr calculating..... 18 of 392.8125\nWhirrrrrr calculating..... 19 of 392.8125\nWhirrrrrr calculating..... 20 of 392.8125\nWhirrrrrr calculating..... 21 of 392.8125\nWhirrrrrr calculating..... 22 of 392.8125\nWhirrrrrr calculating..... 23 of 392.8125\nWhirrrrrr calculating..... 24 of 392.8125\nWhirrrrrr calculating..... 25 of 392.8125\nWhirrrrrr calculating..... 26 of 392.8125\nWhirrrrrr calculating..... 27 of 392.8125\nWhirrrrrr calculating..... 28 of 392.8125\nWhirrrrrr calculating..... 29 of 392.8125\nWhirrrrrr calculating..... 30 of 392.8125\nWhirrrrrr calculating..... 31 of 392.8125\nWhirrrrrr calculating..... 32 of 392.8125\nWhirrrrrr calculating..... 33 of 392.8125\nWhirrrrrr calculating..... 34 of 392.8125\nWhirrrrrr calculating..... 35 of 392.8125\nWhirrrrrr calculating..... 36 of 392.8125\nWhirrrrrr calculating..... 37 of 392.8125\nWhirrrrrr calculating..... 38 of 392.8125\nWhirrrrrr calculating..... 39 of 392.8125\nWhirrrrrr calculating..... 40 of 392.8125\nWhirrrrrr calculating..... 41 of 392.8125\nWhirrrrrr calculating..... 42 of 392.8125\nWhirrrrrr calculating..... 43 of 392.8125\nWhirrrrrr calculating..... 44 of 392.8125\nWhirrrrrr calculating..... 45 of 392.8125\nWhirrrrrr calculating..... 46 of 392.8125\nWhirrrrrr calculating..... 47 of 392.8125\nWhirrrrrr calculating..... 48 of 392.8125\nWhirrrrrr calculating..... 49 of 392.8125\nWhirrrrrr calculating..... 50 of 392.8125\nWhirrrrrr calculating..... 51 of 392.8125\nWhirrrrrr calculating..... 52 of 392.8125\nWhirrrrrr calculating..... 53 of 392.8125\nWhirrrrrr calculating..... 54 of 392.8125\nWhirrrrrr calculating..... 55 of 392.8125\nWhirrrrrr calculating..... 56 of 392.8125\nWhirrrrrr calculating..... 57 of 392.8125\nWhirrrrrr calculating..... 58 of 392.8125\nWhirrrrrr calculating..... 59 of 392.8125\nWhirrrrrr calculating..... 60 of 392.8125\nWhirrrrrr calculating..... 61 of 392.8125\nWhirrrrrr calculating..... 62 of 392.8125\nWhirrrrrr calculating..... 63 of 392.8125\nWhirrrrrr calculating..... 64 of 392.8125\nWhirrrrrr calculating..... 65 of 392.8125\nWhirrrrrr calculating..... 66 of 392.8125\nWhirrrrrr calculating..... 67 of 392.8125\nWhirrrrrr calculating..... 68 of 392.8125\nWhirrrrrr calculating..... 69 of 392.8125\nWhirrrrrr calculating..... 70 of 392.8125\nWhirrrrrr calculating..... 71 of 392.8125\nWhirrrrrr calculating..... 72 of 392.8125\nWhirrrrrr calculating..... 73 of 392.8125\nWhirrrrrr calculating..... 74 of 392.8125\nWhirrrrrr calculating..... 75 of 392.8125\nWhirrrrrr calculating..... 76 of 392.8125\nWhirrrrrr calculating..... 77 of 392.8125\nWhirrrrrr calculating..... 78 of 392.8125\nWhirrrrrr calculating..... 79 of 392.8125\nWhirrrrrr calculating..... 80 of 392.8125\nWhirrrrrr calculating..... 81 of 392.8125\nWhirrrrrr calculating..... 82 of 392.8125\nWhirrrrrr calculating..... 83 of 392.8125\nWhirrrrrr calculating..... 84 of 392.8125\nWhirrrrrr calculating..... 85 of 392.8125\nWhirrrrrr calculating..... 86 of 392.8125\nWhirrrrrr calculating..... 87 of 392.8125\nWhirrrrrr calculating..... 88 of 392.8125\nWhirrrrrr calculating..... 89 of 392.8125\nWhirrrrrr calculating..... 90 of 392.8125\nWhirrrrrr calculating..... 91 of 392.8125\nWhirrrrrr calculating..... 92 of 392.8125\nWhirrrrrr calculating..... 93 of 392.8125\nWhirrrrrr calculating..... 94 of 392.8125\nWhirrrrrr calculating..... 95 of 392.8125\nWhirrrrrr calculating..... 96 of 392.8125\nWhirrrrrr calculating..... 97 of 392.8125\nWhirrrrrr calculating..... 98 of 392.8125\nWhirrrrrr calculating..... 99 of 392.8125\nWhirrrrrr calculating..... 100 of 392.8125\nWhirrrrrr calculating..... 101 of 392.8125\nWhirrrrrr calculating..... 102 of 392.8125\nWhirrrrrr calculating..... 103 of 392.8125\nWhirrrrrr calculating..... 104 of 392.8125\nWhirrrrrr calculating..... 105 of 392.8125\nWhirrrrrr calculating..... 106 of 392.8125\nWhirrrrrr calculating..... 107 of 392.8125\nWhirrrrrr calculating..... 108 of 392.8125\nWhirrrrrr calculating..... 109 of 392.8125\nWhirrrrrr calculating..... 110 of 392.8125\nWhirrrrrr calculating..... 111 of 392.8125\nWhirrrrrr calculating..... 112 of 392.8125\nWhirrrrrr calculating..... 113 of 392.8125\nWhirrrrrr calculating..... 114 of 392.8125\nWhirrrrrr calculating..... 115 of 392.8125\nWhirrrrrr calculating..... 116 of 392.8125\nWhirrrrrr calculating..... 117 of 392.8125\nWhirrrrrr calculating..... 118 of 392.8125\nWhirrrrrr calculating..... 119 of 392.8125\nWhirrrrrr calculating..... 120 of 392.8125\nWhirrrrrr calculating..... 121 of 392.8125\nWhirrrrrr calculating..... 122 of 392.8125\nWhirrrrrr calculating..... 123 of 392.8125\nWhirrrrrr calculating..... 124 of 392.8125\nWhirrrrrr calculating..... 125 of 392.8125\nWhirrrrrr calculating..... 126 of 392.8125\nWhirrrrrr calculating..... 127 of 392.8125\nWhirrrrrr calculating..... 128 of 392.8125\nWhirrrrrr calculating..... 129 of 392.8125\nWhirrrrrr calculating..... 130 of 392.8125\nWhirrrrrr calculating..... 131 of 392.8125\nWhirrrrrr calculating..... 132 of 392.8125\nWhirrrrrr calculating..... 133 of 392.8125\nWhirrrrrr calculating..... 134 of 392.8125\nWhirrrrrr calculating..... 135 of 392.8125\nWhirrrrrr calculating..... 136 of 392.8125\nWhirrrrrr calculating..... 137 of 392.8125\nWhirrrrrr calculating..... 138 of 392.8125\nWhirrrrrr calculating..... 139 of 392.8125\nWhirrrrrr calculating..... 140 of 392.8125\nWhirrrrrr calculating..... 141 of 392.8125\nWhirrrrrr calculating..... 142 of 392.8125\nWhirrrrrr calculating..... 143 of 392.8125\nWhirrrrrr calculating..... 144 of 392.8125\nWhirrrrrr calculating..... 145 of 392.8125\nWhirrrrrr calculating..... 146 of 392.8125\nWhirrrrrr calculating..... 147 of 392.8125\nWhirrrrrr calculating..... 148 of 392.8125\nWhirrrrrr calculating..... 149 of 392.8125\nWhirrrrrr calculating..... 150 of 392.8125\nWhirrrrrr calculating..... 151 of 392.8125\nWhirrrrrr calculating..... 152 of 392.8125\nWhirrrrrr calculating..... 153 of 392.8125\nWhirrrrrr calculating..... 154 of 392.8125\nWhirrrrrr calculating..... 155 of 392.8125\nWhirrrrrr calculating..... 156 of 392.8125\nWhirrrrrr calculating..... 157 of 392.8125\nWhirrrrrr calculating..... 158 of 392.8125\nWhirrrrrr calculating..... 159 of 392.8125\nWhirrrrrr calculating..... 160 of 392.8125\nWhirrrrrr calculating..... 161 of 392.8125\nWhirrrrrr calculating..... 162 of 392.8125\nWhirrrrrr calculating..... 163 of 392.8125\nWhirrrrrr calculating..... 164 of 392.8125\nWhirrrrrr calculating..... 165 of 392.8125\nWhirrrrrr calculating..... 166 of 392.8125\nWhirrrrrr calculating..... 167 of 392.8125\nWhirrrrrr calculating..... 168 of 392.8125\nWhirrrrrr calculating..... 169 of 392.8125\nWhirrrrrr calculating..... 170 of 392.8125\nWhirrrrrr calculating..... 171 of 392.8125\nWhirrrrrr calculating..... 172 of 392.8125\nWhirrrrrr calculating..... 173 of 392.8125\nWhirrrrrr calculating..... 174 of 392.8125\nWhirrrrrr calculating..... 175 of 392.8125\nWhirrrrrr calculating..... 176 of 392.8125\nWhirrrrrr calculating..... 177 of 392.8125\nWhirrrrrr calculating..... 178 of 392.8125\nWhirrrrrr calculating..... 179 of 392.8125\nWhirrrrrr calculating..... 180 of 392.8125\nWhirrrrrr calculating..... 181 of 392.8125\nWhirrrrrr calculating..... 182 of 392.8125\nWhirrrrrr calculating..... 183 of 392.8125\nWhirrrrrr calculating..... 184 of 392.8125\nWhirrrrrr calculating..... 185 of 392.8125\nWhirrrrrr calculating..... 186 of 392.8125\nWhirrrrrr calculating..... 187 of 392.8125\nWhirrrrrr calculating..... 188 of 392.8125\nWhirrrrrr calculating..... 189 of 392.8125\nWhirrrrrr calculating..... 190 of 392.8125\nWhirrrrrr calculating..... 191 of 392.8125\nWhirrrrrr calculating..... 192 of 392.8125\nWhirrrrrr calculating..... 193 of 392.8125\nWhirrrrrr calculating..... 194 of 392.8125\nWhirrrrrr calculating..... 195 of 392.8125\nWhirrrrrr calculating..... 196 of 392.8125\nWhirrrrrr calculating..... 197 of 392.8125\nWhirrrrrr calculating..... 198 of 392.8125\nWhirrrrrr calculating..... 199 of 392.8125\nWhirrrrrr calculating..... 200 of 392.8125\nWhirrrrrr calculating..... 201 of 392.8125\nWhirrrrrr calculating..... 202 of 392.8125\nWhirrrrrr calculating..... 203 of 392.8125\nWhirrrrrr calculating..... 204 of 392.8125\nWhirrrrrr calculating..... 205 of 392.8125\nWhirrrrrr calculating..... 206 of 392.8125\nWhirrrrrr calculating..... 207 of 392.8125\nWhirrrrrr calculating..... 208 of 392.8125\nWhirrrrrr calculating..... 209 of 392.8125\nWhirrrrrr calculating..... 210 of 392.8125\nWhirrrrrr calculating..... 211 of 392.8125\nWhirrrrrr calculating..... 212 of 392.8125\nWhirrrrrr calculating..... 213 of 392.8125\nWhirrrrrr calculating..... 214 of 392.8125\nWhirrrrrr calculating..... 215 of 392.8125\nWhirrrrrr calculating..... 216 of 392.8125\nWhirrrrrr calculating..... 217 of 392.8125\nWhirrrrrr calculating..... 218 of 392.8125\nWhirrrrrr calculating..... 219 of 392.8125\nWhirrrrrr calculating..... 220 of 392.8125\nWhirrrrrr calculating..... 221 of 392.8125\nWhirrrrrr calculating..... 222 of 392.8125\nWhirrrrrr calculating..... 223 of 392.8125\nWhirrrrrr calculating..... 224 of 392.8125\nWhirrrrrr calculating..... 225 of 392.8125\nWhirrrrrr calculating..... 226 of 392.8125\nWhirrrrrr calculating..... 227 of 392.8125\nWhirrrrrr calculating..... 228 of 392.8125\nWhirrrrrr calculating..... 229 of 392.8125\nWhirrrrrr calculating..... 230 of 392.8125\nWhirrrrrr calculating..... 231 of 392.8125\nWhirrrrrr calculating..... 232 of 392.8125\nWhirrrrrr calculating..... 233 of 392.8125\nWhirrrrrr calculating..... 234 of 392.8125\nWhirrrrrr calculating..... 235 of 392.8125\nWhirrrrrr calculating..... 236 of 392.8125\nWhirrrrrr calculating..... 237 of 392.8125\nWhirrrrrr calculating..... 238 of 392.8125\nWhirrrrrr calculating..... 239 of 392.8125\nWhirrrrrr calculating..... 240 of 392.8125\nWhirrrrrr calculating..... 241 of 392.8125\nWhirrrrrr calculating..... 242 of 392.8125\nWhirrrrrr calculating..... 243 of 392.8125\nWhirrrrrr calculating..... 244 of 392.8125\nWhirrrrrr calculating..... 245 of 392.8125\nWhirrrrrr calculating..... 246 of 392.8125\nWhirrrrrr calculating..... 247 of 392.8125\nWhirrrrrr calculating..... 248 of 392.8125\nWhirrrrrr calculating..... 249 of 392.8125\nWhirrrrrr calculating..... 250 of 392.8125\nWhirrrrrr calculating..... 251 of 392.8125\nWhirrrrrr calculating..... 252 of 392.8125\nWhirrrrrr calculating..... 253 of 392.8125\nWhirrrrrr calculating..... 254 of 392.8125\nWhirrrrrr calculating..... 255 of 392.8125\nWhirrrrrr calculating..... 256 of 392.8125\nWhirrrrrr calculating..... 257 of 392.8125\nWhirrrrrr calculating..... 258 of 392.8125\nWhirrrrrr calculating..... 259 of 392.8125\nWhirrrrrr calculating..... 260 of 392.8125\nWhirrrrrr calculating..... 261 of 392.8125\nWhirrrrrr calculating..... 262 of 392.8125\nWhirrrrrr calculating..... 263 of 392.8125\nWhirrrrrr calculating..... 264 of 392.8125\nWhirrrrrr calculating..... 265 of 392.8125\nWhirrrrrr calculating..... 266 of 392.8125\nWhirrrrrr calculating..... 267 of 392.8125\nWhirrrrrr calculating..... 268 of 392.8125\nWhirrrrrr calculating..... 269 of 392.8125\nWhirrrrrr calculating..... 270 of 392.8125\nWhirrrrrr calculating..... 271 of 392.8125\nWhirrrrrr calculating..... 272 of 392.8125\nWhirrrrrr calculating..... 273 of 392.8125\nWhirrrrrr calculating..... 274 of 392.8125\nWhirrrrrr calculating..... 275 of 392.8125\nWhirrrrrr calculating..... 276 of 392.8125\nWhirrrrrr calculating..... 277 of 392.8125\nWhirrrrrr calculating..... 278 of 392.8125\nWhirrrrrr calculating..... 279 of 392.8125\nWhirrrrrr calculating..... 280 of 392.8125\nWhirrrrrr calculating..... 281 of 392.8125\nWhirrrrrr calculating..... 282 of 392.8125\nWhirrrrrr calculating..... 283 of 392.8125\nWhirrrrrr calculating..... 284 of 392.8125\nWhirrrrrr calculating..... 285 of 392.8125\nWhirrrrrr calculating..... 286 of 392.8125\nWhirrrrrr calculating..... 287 of 392.8125\nWhirrrrrr calculating..... 288 of 392.8125\nWhirrrrrr calculating..... 289 of 392.8125\nWhirrrrrr calculating..... 290 of 392.8125\nWhirrrrrr calculating..... 291 of 392.8125\nWhirrrrrr calculating..... 292 of 392.8125\nWhirrrrrr calculating..... 293 of 392.8125\nWhirrrrrr calculating..... 294 of 392.8125\nWhirrrrrr calculating..... 295 of 392.8125\nWhirrrrrr calculating..... 296 of 392.8125\nWhirrrrrr calculating..... 297 of 392.8125\nWhirrrrrr calculating..... 298 of 392.8125\nWhirrrrrr calculating..... 299 of 392.8125\nWhirrrrrr calculating..... 300 of 392.8125\nWhirrrrrr calculating..... 301 of 392.8125\nWhirrrrrr calculating..... 302 of 392.8125\nWhirrrrrr calculating..... 303 of 392.8125\nWhirrrrrr calculating..... 304 of 392.8125\nWhirrrrrr calculating..... 305 of 392.8125\nWhirrrrrr calculating..... 306 of 392.8125\nWhirrrrrr calculating..... 307 of 392.8125\nWhirrrrrr calculating..... 308 of 392.8125\nWhirrrrrr calculating..... 309 of 392.8125\nWhirrrrrr calculating..... 310 of 392.8125\nWhirrrrrr calculating..... 311 of 392.8125\nWhirrrrrr calculating..... 312 of 392.8125\nWhirrrrrr calculating..... 313 of 392.8125\nWhirrrrrr calculating..... 314 of 392.8125\nWhirrrrrr calculating..... 315 of 392.8125\nWhirrrrrr calculating..... 316 of 392.8125\nWhirrrrrr calculating..... 317 of 392.8125\nWhirrrrrr calculating..... 318 of 392.8125\nWhirrrrrr calculating..... 319 of 392.8125\nWhirrrrrr calculating..... 320 of 392.8125\nWhirrrrrr calculating..... 321 of 392.8125\nWhirrrrrr calculating..... 322 of 392.8125\nWhirrrrrr calculating..... 323 of 392.8125\nWhirrrrrr calculating..... 324 of 392.8125\nWhirrrrrr calculating..... 325 of 392.8125\nWhirrrrrr calculating..... 326 of 392.8125\nWhirrrrrr calculating..... 327 of 392.8125\nWhirrrrrr calculating..... 328 of 392.8125\nWhirrrrrr calculating..... 329 of 392.8125\nWhirrrrrr calculating..... 330 of 392.8125\nWhirrrrrr calculating..... 331 of 392.8125\nWhirrrrrr calculating..... 332 of 392.8125\nWhirrrrrr calculating..... 333 of 392.8125\nWhirrrrrr calculating..... 334 of 392.8125\nWhirrrrrr calculating..... 335 of 392.8125\nWhirrrrrr calculating..... 336 of 392.8125\nWhirrrrrr calculating..... 337 of 392.8125\nWhirrrrrr calculating..... 338 of 392.8125\nWhirrrrrr calculating..... 339 of 392.8125\nWhirrrrrr calculating..... 340 of 392.8125\nWhirrrrrr calculating..... 341 of 392.8125\nWhirrrrrr calculating..... 342 of 392.8125\nWhirrrrrr calculating..... 343 of 392.8125\nWhirrrrrr calculating..... 344 of 392.8125\nWhirrrrrr calculating..... 345 of 392.8125\nWhirrrrrr calculating..... 346 of 392.8125\nWhirrrrrr calculating..... 347 of 392.8125\nWhirrrrrr calculating..... 348 of 392.8125\nWhirrrrrr calculating..... 349 of 392.8125\nWhirrrrrr calculating..... 350 of 392.8125\nWhirrrrrr calculating..... 351 of 392.8125\nWhirrrrrr calculating..... 352 of 392.8125\nWhirrrrrr calculating..... 353 of 392.8125\nWhirrrrrr calculating..... 354 of 392.8125\nWhirrrrrr calculating..... 355 of 392.8125\nWhirrrrrr calculating..... 356 of 392.8125\nWhirrrrrr calculating..... 357 of 392.8125\nWhirrrrrr calculating..... 358 of 392.8125\nWhirrrrrr calculating..... 359 of 392.8125\nWhirrrrrr calculating..... 360 of 392.8125\nWhirrrrrr calculating..... 361 of 392.8125\nWhirrrrrr calculating..... 362 of 392.8125\nWhirrrrrr calculating..... 363 of 392.8125\nWhirrrrrr calculating..... 364 of 392.8125\nWhirrrrrr calculating..... 365 of 392.8125\nWhirrrrrr calculating..... 366 of 392.8125\nWhirrrrrr calculating..... 367 of 392.8125\nWhirrrrrr calculating..... 368 of 392.8125\nWhirrrrrr calculating..... 369 of 392.8125\nWhirrrrrr calculating..... 370 of 392.8125\nWhirrrrrr calculating..... 371 of 392.8125\nWhirrrrrr calculating..... 372 of 392.8125\nWhirrrrrr calculating..... 373 of 392.8125\nWhirrrrrr calculating..... 374 of 392.8125\nWhirrrrrr calculating..... 375 of 392.8125\nWhirrrrrr calculating..... 376 of 392.8125\nWhirrrrrr calculating..... 377 of 392.8125\nWhirrrrrr calculating..... 378 of 392.8125\nWhirrrrrr calculating..... 379 of 392.8125\nWhirrrrrr calculating..... 380 of 392.8125\nWhirrrrrr calculating..... 381 of 392.8125\nWhirrrrrr calculating..... 382 of 392.8125\nWhirrrrrr calculating..... 383 of 392.8125\nWhirrrrrr calculating..... 384 of 392.8125\nWhirrrrrr calculating..... 385 of 392.8125\nWhirrrrrr calculating..... 386 of 392.8125\nWhirrrrrr calculating..... 387 of 392.8125\nWhirrrrrr calculating..... 388 of 392.8125\nWhirrrrrr calculating..... 389 of 392.8125\nWhirrrrrr calculating..... 390 of 392.8125\nWhirrrrrr calculating..... 391 of 392.8125\nWhirrrrrr calculating..... 392 of 392.8125\n"
    }
   ],
   "source": [
    "\n",
    "var = 0.0\n",
    "count_var =0\n",
    "for images, _ in tr_dl:\n",
    "    batch_samples = images.size(0)\n",
    "    images = images.view(batch_samples, images.size(1), -1)\n",
    "    var += ((images - mean.unsqueeze(1))**2).sum([0,2])\n",
    "    print(f\"Whirrrrrr calculating..... {count_var} of {train_size/batch_sz}\")\n",
    "    count_var+= 1\n",
    "std = torch.sqrt(var / (len(tr_dl.dataset)*720*1280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([63.4003, 64.1523, 64.4491])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Moderate_tr_stats = mean, std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean is tensor([ 98.2207, 101.6702, 102.9898])\n",
    "std is tensor([63.4003, 64.1523, 64.4491])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Normalize(mean=tensor([ 98.2207, 101.6702, 102.9898]), std=tensor([63.4003, 64.1523, 64.4491]))"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "transforms.Normalize(*Moderate_tr_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "*************MAKE SURE THE PATH FILE IN THE FOR LOOP IS THE BASE IMAGE DIRECTORY ON YOUR COMPUTER**************\n"
    }
   ],
   "source": [
    "normed_dataset = ModerateDataset(trans_on=True, transform=transforms.Normalize(*Moderate_tr_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_dl = DataLoader(normed_dataset,  batch_size=batch_sz, shuffle=True,  num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[tensor([[[[2, 2, 2,  ..., 3, 3, 3],\n           [2, 2, 2,  ..., 3, 3, 3],\n           [2, 2, 2,  ..., 3, 3, 3],\n           ...,\n           [3, 3, 3,  ..., 3, 3, 3],\n           [3, 3, 3,  ..., 3, 3, 3],\n           [3, 3, 3,  ..., 3, 3, 3]],\n \n          [[2, 2, 2,  ..., 2, 2, 2],\n           [2, 2, 2,  ..., 2, 2, 2],\n           [2, 2, 2,  ..., 2, 2, 2],\n           ...,\n           [2, 2, 2,  ..., 3, 3, 3],\n           [2, 2, 2,  ..., 3, 3, 3],\n           [2, 2, 2,  ..., 3, 3, 3]],\n \n          [[2, 2, 2,  ..., 2, 2, 2],\n           [2, 2, 2,  ..., 2, 2, 2],\n           [2, 2, 2,  ..., 2, 2, 2],\n           ...,\n           [2, 2, 2,  ..., 3, 3, 3],\n           [2, 2, 2,  ..., 3, 3, 3],\n           [2, 2, 2,  ..., 3, 3, 3]]],\n \n \n         [[[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [2, 2, 2,  ..., 1, 1, 1],\n           [2, 2, 2,  ..., 1, 1, 1],\n           [2, 2, 2,  ..., 1, 1, 1]],\n \n          [[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [2, 2, 2,  ..., 1, 1, 1],\n           [2, 2, 2,  ..., 1, 1, 1],\n           [2, 2, 2,  ..., 1, 1, 1]],\n \n          [[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0]]],\n \n \n         [[[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]],\n \n          [[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]],\n \n          [[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0],\n           [0, 0, 0,  ..., 0, 0, 0]]],\n \n \n         ...,\n \n \n         [[[3, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 3, 3, 3],\n           [1, 1, 1,  ..., 3, 3, 3],\n           [1, 1, 2,  ..., 0, 3, 3]],\n \n          [[2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 3, 3, 3],\n           [1, 1, 1,  ..., 3, 3, 3],\n           [1, 1, 1,  ..., 3, 3, 3]],\n \n          [[2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           [2, 2, 2,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 2, 3, 3],\n           [1, 1, 1,  ..., 2, 3, 3],\n           [1, 1, 1,  ..., 3, 3, 2]]],\n \n \n         [[[4, 4, 3,  ..., 0, 0, 0],\n           [4, 4, 4,  ..., 0, 0, 0],\n           [4, 4, 4,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]],\n \n          [[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]],\n \n          [[3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           [3, 3, 3,  ..., 0, 0, 0],\n           ...,\n           [1, 1, 1,  ..., 0, 0, 0],\n           [1, 1, 1,  ..., 0, 0, 0],\n           [1, 1, 1,  ..., 0, 0, 0]]],\n \n \n         [[[0, 0, 0,  ..., 2, 2, 2],\n           [0, 0, 0,  ..., 2, 2, 2],\n           [0, 0, 0,  ..., 2, 2, 2],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]],\n \n          [[1, 1, 1,  ..., 2, 2, 2],\n           [0, 1, 1,  ..., 2, 2, 2],\n           [0, 0, 1,  ..., 2, 2, 2],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]],\n \n          [[1, 1, 1,  ..., 2, 2, 2],\n           [0, 1, 1,  ..., 2, 2, 2],\n           [0, 1, 1,  ..., 2, 2, 2],\n           ...,\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1],\n           [1, 1, 1,  ..., 1, 1, 1]]]], dtype=torch.uint8),\n tensor([[[0.0415, 0.0415, 0.0415,  ..., 0.1278, 0.1278, 0.1278],\n          [0.0414, 0.0414, 0.0414,  ..., 0.1273, 0.1272, 0.1272],\n          [0.0413, 0.0413, 0.0413,  ..., 0.1267, 0.1267, 0.1267],\n          ...,\n          [0.0000, 0.0000, 0.0000,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0042, 0.0042, 0.0042],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0042, 0.0042, 0.0042]],\n \n         [[0.0434, 0.0434, 0.0434,  ..., 0.1295, 0.1295, 0.1294],\n          [0.0433, 0.0433, 0.0433,  ..., 0.1289, 0.1289, 0.1288],\n          [0.0432, 0.0432, 0.0432,  ..., 0.1283, 0.1283, 0.1283],\n          ...,\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n \n         [[0.0435, 0.0435, 0.0435,  ..., 0.1296, 0.1295, 0.1295],\n          [0.0434, 0.0434, 0.0434,  ..., 0.1290, 0.1289, 0.1289],\n          [0.0433, 0.0433, 0.0433,  ..., 0.1284, 0.1284, 0.1284],\n          ...,\n          [0.0000, 0.0000, 0.0000,  ..., 0.0004, 0.0005, 0.0005],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0004, 0.0004, 0.0005],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0004, 0.0004, 0.0004]],\n \n         ...,\n \n         [[0.0433, 0.0433, 0.0433,  ..., 0.1321, 0.1320, 0.1320],\n          [0.0432, 0.0432, 0.0432,  ..., 0.1314, 0.1314, 0.1314],\n          [0.0431, 0.0431, 0.0431,  ..., 0.1308, 0.1308, 0.1308],\n          ...,\n          [0.0002, 0.0002, 0.0002,  ..., 0.0063, 0.0063, 0.0063],\n          [0.0002, 0.0002, 0.0002,  ..., 0.0063, 0.0063, 0.0063],\n          [0.0002, 0.0002, 0.0002,  ..., 0.0063, 0.0063, 0.0064]],\n \n         [[0.0435, 0.0435, 0.0435,  ..., 0.1305, 0.1305, 0.1305],\n          [0.0434, 0.0434, 0.0434,  ..., 0.1299, 0.1299, 0.1298],\n          [0.0433, 0.0433, 0.0433,  ..., 0.1293, 0.1292, 0.1292],\n          ...,\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n \n         [[0.0421, 0.0421, 0.0421,  ..., 0.1336, 0.1336, 0.1335],\n          [0.0420, 0.0420, 0.0420,  ..., 0.1330, 0.1329, 0.1329],\n          [0.0419, 0.0419, 0.0419,  ..., 0.1323, 0.1323, 0.1323],\n          ...,\n          [0.0037, 0.0037, 0.0037,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0037, 0.0037, 0.0037,  ..., 0.0000, 0.0000, 0.0000],\n          [0.0037, 0.0037, 0.0037,  ..., 0.0000, 0.0000, 0.0000]]])]"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "next(iter(normed_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}